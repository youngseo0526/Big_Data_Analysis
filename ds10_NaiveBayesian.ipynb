{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Navie Bayesian\n",
    "\n",
    "Last updated 20201122SUN1100 20190826MON1700\n",
    "\n",
    "## 목적\n",
    "\n",
    "## 목차\n",
    "* 5.2 문제\n",
    "* 5.3 확률에 대한 관점\n",
    "* 5.4 베이지안 확률\n",
    "    * 5.4.1 판단 오류\n",
    "    * 5.4.2 베이지안 추론\n",
    "    * 5.4.3 사전확률\n",
    "    * 5.4.4 가능도\n",
    "* 5.5 Navie Bayesian algorithm\n",
    "* 문제 1: 일반적인 확률\n",
    "* 문제 2: 조건부 확률\n",
    "* 문제 3: 베이지안\n",
    "* 문제 4: Naive Bayesian 추론\n",
    "* 5.6 이항 베이지안\n",
    "* 문제: Sklearn make_classification으로 생성된 데이터에 대해 이진 베이지안 모델\n",
    "* 5.7 정규분포 베이지안\n",
    "* 5.8 다항 베이지안 multinomial Bayesian\n",
    "* 문제: 트윗 정서 분석\n",
    "\n",
    "* toDO: house-votes-84.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.2 문제\n",
    "\n",
    "스팸인지 아닌지, 긍정인지 부정인지, 불량인지 아닌지와 같은 **분류** 문제가 있다고 하자.\n",
    "Logistic Regression, 의사결정트리와 같은 지도기계학습과 더불어 Naive Bayesian도 분류에 적용할 수 있다.\n",
    "NB는 베이즈 정리 Bayes' theorem에 따라 확률계산을 하지만, 변인 간에 **독립적, 즉 naive한 관계**를 가정하고 적용된다.\n",
    "\n",
    "확률을 계산해서 분류의 문제를 푸는 경우에 유의할 점이 있다.\n",
    "* 속성의 값이 **비연속적**, 예를 들어 단어의 발생빈도에 따라 정서를 분류하거나, 또는 **연속적**인 값을 가지는 몸무게, 키, 발크기에 따라 성별을 구분하는 경우,\n",
    "* 분류하고자 하는 대상이 **이진적 binary** 또는 **다항적 multiclass**인지에 따라,\n",
    "* 또는 **사전확률**을 알 수 있는지, 알 수 있다면 어떤 분포를 따르는지 분별해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.3 확률에 대한 관점\n",
    "\n",
    "확률에 대한 관점은 빈도주의자와 베이지안으로 구분하여 볼 수 있다.\n",
    "**빈도주의자 frequentists**는 확률이란 오랫 동안 반복하면 기대하는 빈도, 즉 P(A) = n/N, n은 N회 반복했을 경우 A의 기대 값이라고 주장한다 (objective, physical). 주사위를 던지는 경우, 발생할 수 있는 경우의 수는 1, 2, 3, 4, 5, 6이고, 주사위가 공평하게 만들어져 있기 때문에 객관적으로 발생할 수 있는 빈도는 1/6로 확률이 정해진다. 무작위로, 충분히 샘플링을 하여 발생한 과거의 데이터로 계산한다. 1회 던지는 경우, 1/6이라는 정확한 확률이 나오지 않을 수 있다. 사전 지식은 무의미하게 된다. 빈도주의자는 가설을 설정하고, 실험을 하고, 결과를 통해 가설이 맞는지 통계적 추정을 할 경우, 그 값이 정해져 있다고 본다. 예를 들어, 모집단이 정규분포를 따른다고 하면, 평균은 어떤 확률로 신뢰구간 내에 반드시 그 값이 존재한다.\n",
    "\n",
    "**베이지안 Bayesian**은 확률이란 불확실한 사건에 대한 주관이나 자신이 믿고 있는 정도에 따라 확률이 정해진다고 생각한다 (epistemic, evidential, subjective, degree of belief). \n",
    "주사위를 던지는 경우에도 현재의 주관적 믿음에 따라 확률을 정하고, 정보가 추가적으로 주어지면, 그에 따라 갱신된다. 따라서 정보가 부족하므로 1) 사전확률prior을 정하고, 2) 주어지는 증거에 따라 갱신likelihood, 3) 사후확률posterior 추정한다. 평균 값을 추정을 할 경우, 그 값은 불확실하며 분포에 따라 신뢰구간 내에 존재할 수도 있고 없을 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.4 베이지안 확률\n",
    "\n",
    "### 5.4.1 판단 오류\n",
    "\n",
    "베이지안으로 생각하면 판단의 오류가 왜 비롯되는지 알 수 있다.\n",
    "어떤 사람이 무죄임에도 불구하고, 검사는 **증거가 발견되었으니 당신은 유죄**라고 한다면 얼마나 억울하겠는가?\n",
    "\n",
    "| 유죄  | 무죄 | 합계\n",
    "-----|-----|-----\n",
    "증거 | 1 | 10 | 11\n",
    "증거 x | 0 | 9,999,990 | 9,999,990\n",
    "합계 | 1 | 10,000,000 | 10,000,001\n",
    "\n",
    "(출처: 위키피디아)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "필요한 것은 p(유죄|증거), 증거가 발견되었을 경우, 그 사람이 유죄인지 무죄인지를 따져야 한다.\n",
    "그러나 **P(증거|무죄), 즉 무죄이지만 증거가 발견될 백만분의 1**, 표에서 보듯이, **확률이 매우 적기 때문에 유죄**라는 판단을 하는 것이다.\n",
    "\n",
    "즉 P(유죄|증거)를 올바르게 판단하려면, P(증거|유죄)에 P(유죄)를 곱해서 P(증거)로 나눈 값을 계산해야 한다.\n",
    "* P(유죄) = $\\frac{1}{10,000,001}$ 그 사람이 유죄일 **사전확률**. 그 사람이 유죄라는 확률은 미리 알기 어렵다.\n",
    "* P(증거|유죄) = $\\frac{1}{1}$, 그 사람이 유죄라면 증거가 일치하는 확률\n",
    "* P(증거) = $\\frac{11}{10,000,001}$ 유무죄 상관없이 증거가 발견되고 일치할 확률\n",
    "\n",
    "간과하기 쉬운 것은, 무죄라고 추정되지만 증거가 발견될 확률이 적지만, 10/10,000,000건이 존재한다는 사실이다. 예를 들어, 지문이 흉기에서 발견되었지만, 사건 이전에 용의자가 만지거나, 사건에 개입되면서 닿았거나, 또는 사건 후에 만져서 생겼을 수 도 있다. 또는 용의자가 거의 확실한 알리바이를 가지고 있다면 유죄일 확률은 지문이 발견될 확률보다 매우 적게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "잘못된 판단은 **p(증거|유죄) = p(유죄|증거)**라고 믿는 것이다.\n",
    "즉, \"유죄이므로 증거가 나왔다\"를 \"증거가 나왔으니 유죄다\"라고 판단, 예를 들어, 지문이 나왔다고 해서, 그 사람을 범인으로 단정해서는 안되는 것이다. **증거가 나왔다고 하더라도 유죄가 아니라 무죄일 확률**이 있는 것이다. 매우 확실한 알리바이를 가지고 있다면, 지문이 나오든 나오지 않든 범인이 아닐 가능성이 높은 것이다. 베이지안은 이런 판단이 잘 못되었다는 것을 알려주고 있다.\n",
    "\n",
    "이런 판단은 일상생활에서도 많다.\n",
    "'몇 일 동안이나 답전화를 하지 않다니, 나를 더 이상 사랑하지 않나봐',\n",
    "'어떻게 나에게 그런 말을 할 수 있어, 아주 나쁜 사람이야'라는 판단도 역시 오류일 수 있다.\n",
    "\n",
    "어떤 증거에 따라 그 사람을 판단하는, 즉 P(그 사람이 나를 더 이상 사랑하지 않아|몇 일 동안 답전화가 없다)라는 $P(\\theta|D)$를 확신하는 것은 $P(D|\\theta)$를 충분히 고려하지 못하는 오류를 포함할 수 있다는 점이다.\n",
    "그 사람이 다른 이유로 답전화를 못하거나, 학교에서 성적이 F를 받고 화를 내거나 할 수 있는 확률이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.4.2 베이지안 추론\n",
    "\n",
    "베이지안에서는 어떤 가설을 평가하기 위해, 먼저 (1) 사전확률 $P(\\theta)$을 예상하고, 여기에 관측된 데이터로부터 계산된 (2) 가능성 likelihood $P(D|\\theta)$을 곱하고, (3) P(D)로 나누어, 사후확률을 계산하여 추론하게 된다. \n",
    "\n",
    "$P(\\theta|D) = \\frac{P(D|\\theta) P(\\theta)}{P(D)}$\n",
    "\n",
    "P(D)는 사후확률을 확률분포로 만들게 하는 정규화 상수이다. 즉 P(D)로 나누어주면 사후확률분포의 합이 1이 되게 한다.\n",
    "추론을 할 때는 최대값을 구하기만 하면 되므로, 위 식에서 분모 P(D)를 생략하면 아래와 같다. 좌측 사후확률이 우측 계산식과 동일하지 않기 때문에, 비례관계에 있다고 (propotional to) 한다.\n",
    "\n",
    "$P(\\theta|D) \\propto P(D|\\theta) \\cdot P(\\theta)$\n",
    "\n",
    "즉 사후확률은 ∝ 가능도 × 사전확률로 계산할 수 있다.\n",
    "\n",
    "또는, 로그를 취해서, $log P(D | \\theta) + log P(\\theta)$을 사용해서 추론할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.4.3 사전확률\n",
    "\n",
    "베이지안에서의 사전확률은 어떤 사건이 얼마나 발생할 것인지\n",
    "아무런 증거도 없는 상황에서의 **개인적인 믿음의 정도**를 말한다.\n",
    "예를 들어, 야구에서 타자가 안타를 칠 것인지 아닌지 100회 출장에서 25회의 안타를 기록했다고 하면 P(안타)=0.25이고 아닌 경우는 0.75가 된다.\n",
    "\n",
    "사전확률을 **모르는 경우, 균등분포 uniform distribution**을 따른다고 가정하고, 모든 사건이 동일한 확률로 발생한다고 예상할 수 있다. 또는 사전확률 $P(\\theta)$의 분포가 사후확률 $p(\\theta|D)$의 분포와 같은 유형이라고 가정할 수도 있다. 실제 계산해 보면, 사후확률은 사전확률에 likelihood를 갱신하기 때문에 매우 유사한 분포를 가진다.\n",
    "이 경우 사전, 사후 확률의 분포를 컬레분포, conjugate distributions라고 하고, **가능도를 갱신할 때 쓰이는 사전확률을 '켤레 사전확률, conjugate prior'**이라고 한다.\n",
    "예를 들어, 가능도가 정규분포를 따르고 이 경우 **사전확률을 정규분포로 하면 사후확률도 컬레로 정규분포**를 따르게 된다. likelihood가 특정 분포를 따른다고 가정할 경우, 사전확률과 사후확률은 동일한 분포를 따르게 된다 (Raiffa & Schlaifer, 1961). 이 가정에 따르면, **사후확률을 계산할 때, 분모계산을 하지 않게 하지 않아도** 된다. 예를 들어, 동전던지기는 **이항분포를 가진 사후확률의 사전확률도 이항분포**라고 할 경우, **베타분포를 conjugate prior로 사용**한다. \n",
    "\n",
    "* likelihood가 정규분포를 따르면 Gaussian, 컬레확률은 Gaussian\n",
    "* 다항분포일 경우, 컬레확률은 Dirichlet (예: 토픽모델링 lda)\n",
    "* 포아손분포일 경우, gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.4.4 가능도\n",
    "\n",
    "가능도 likelihood를 계산할 경우, 속성 간의 관계성을 무시하고 계산한다. **독립적**이란 사건의 발생이 서로 영향이 주고 받지 않는다는 의미이다. 동전을 2개 던지면 앞면이 나올지 뒷면이 나올지 서로 독립적이다.\n",
    "예를 들어, 어떤 단어들이 발생한 경우 어느 클래스에 속하는지 계산한다고 하자. 단어간의 관계가 서로 독립적이라고 가정하고 **각 단어의 발생확률만을 서로 곱**하여 확률을 계산한다. 그러면 아래 첫번 째 식은 두번째 식으로 변환될 수 있다.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(C_k \\vert x_1, \\dots, x_n)\n",
    "    & \\varpropto P(C_k, x_1, \\dots, x_n) \\\\\n",
    "    & \\varpropto P(C_k) P(x_1 \\vert C_k) \\\n",
    "         P(x_2\\vert C_k) P(x_3\\vert C_k) \\cdots \\\\\n",
    "    & \\varpropto P(C_k) \\prod_{i=1}^n P(x_i \\vert C_k)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "이런 가정을 하는 이유는 계산의 복잡성을 줄이기 위한 가정이다. 예를 들어, 속성이 2가지 값을 갖고, 이러한 속성이 5개 있다면 $2^5=512$ 경우의 확률을 계산해야 하지만, NB의 경우, $2 \\times 5 = 10$개를 계산하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "계산하면서, 식에서 발생한 건수가 없어서 확률 계산을 하면서 0이 되는 문제가 있다.\n",
    "0값으로 나누어지는 것을 막기 위해 임의로 적은 수를 더하여 주는 Laplace smooting을 적용하게 된다.\n",
    "\n",
    "$ P(x)=\\frac{count(x) + \\alpha}{N + \\alpha \\vert x \\vert}$\n",
    "\n",
    "* count(x) x의 발생건수\n",
    "* |x|는 발생가능한 사건의 수\n",
    "* $\\alpha$는 조절변수. 0이면 조절이 없게 되고, 1이면 add-one smoothing\n",
    "* N은 x의 총발생건수\n",
    "\n",
    "예를 들어, 메시지는 스팸이거나 아니 경우 2가지가 있다고 하자.\n",
    "\n",
    "$ P(메시지가 스팸) = \\frac {스팸메시지갯수 + k} {전체메시지갯수 + k \\times 메시지분류갯수}$\n",
    "\n",
    "전체3개 가운데 3개 모두 스팸인 경우, 그리고 2가지로 분류하므로 k=2\n",
    "\n",
    "$ \\frac{3 + 2 }{3 + 2 \\times 2}= \\frac {5}{7}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.5 Navie Bayesian algorithm\n",
    "\n",
    "* input: 문서와 문서별로 할당된 클래스 (D, c)\n",
    "* output: 문서의 분류 클래스\n",
    "* for c $\\in$ C 모든 클래스에 대해 ($\\in$은 \"belongs to\" 혹은 \"is in the set of\", 즉 C에 속하는 모든 c)\n",
    "    * $ \\frac{N_c} {N}$ 클래스가 발생할 사전확률을 구한다 ($N_c$ 클래스 발생갯수, N: 전체갯수)\n",
    "    * 가능도 likelihood를 계산한다.\n",
    "    * 사후확률을 계산한다.\n",
    "        $P(\\theta | D) = P(D)$\n",
    "    * 갱신된 확률에 따라 추론 Bayesian Inference 한다.\n",
    "        * ML (Maximum likelihood estimation)\n",
    "            * $c_{ML}=argmax_c P(D | \\theta)$, 우도가 최대인 가설, c가 맞다고 추론\n",
    "        * MAP (Maximum a posteriori estimation)\n",
    "            * $c_{MAP}=argmax_c P(\\theta | D)$, 우도가 아니라, 사후확률이 최대인 가설이 맞다고 추론            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 1: 일반적인 확률\n",
    "\n",
    "7개의 공이 있다. 이 가운데 하얀 공 3 (W W W), 검은 공 4개 (B B B B)라고 하자.\n",
    "* p(W) = 3/7\n",
    "* p(B) = 4/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 2: 조건부 확률\n",
    "\n",
    "가방이 B1, B2가 있다고 하자. 흰공W과 검은공B이 가방에 나누어져서 들어있다고 하자.\n",
    "* B1에는 흰공W 2개 검은공B 2개,\n",
    "* B2에는 흰공W 1개 검은공B 2개가 들어있다고 하자.\n",
    "\n",
    "|    | 흰공 W | 검은공 B |\n",
    "|----|---|---|\n",
    "| 가방 B1 | 2 | 2 |\n",
    "| 가방 B2 | 1 | 2 |\n",
    "\n",
    "흰공W 이고, B2에서 나왔을 확률 $P(A=B2|B=W)$을 계산해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "조건부확률은 계산하면:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(A \\vert B) &= \\frac{P(A \\cap B)}{P(B)} \\\\\n",
    "    & = \\frac{P(A) \\times P(B)}{P(B)}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "* $P(A=B2|B=W) =\\frac{P(B2\\ and\\ W)}{P(W)} = \\frac{1/7}{3/7}=1/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 문제 3: 베이지안\n",
    "\n",
    "위의 조건부확률을 베이지안으로 풀어보자.\n",
    "\n",
    "* 위에서 흰공W이 뽑힌 경우, B2에서 나왔을 확률 $P(A=B2|B=W) = \\frac{P(B2\\ and\\ W)}{P(W)}$\n",
    "* 주머니B2를 선택해서 공을 하나 뽑을 경우 흰 공일 확률로 바꾸어 쓰면:\n",
    "    * $P(B=W|A=B2) = \\frac{P(W\\ and\\ B2)}{P(B2)} = P(W|B2) \\times P(B2)$\n",
    "* 위 식에 대입하면:\n",
    "    * $P(A=B2|B=W) = \\frac{P(W|B2) P(B2)}{P(W)}$\n",
    "\n",
    "이 베이지안 식에 따라 흰공이 나왔는데, 가방2에서 나왔을 확률을 계산하면:\n",
    "* $P(A=B2|B=W)=\\frac{P(W|B2) P(B2)}{P(W)} = \\frac{(1/3)(3/7)}{(3/7)}=1/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "또 다른 예를 풀어보자. 다음과 같은 경우의 수가 있다고 하자.\n",
    "\n",
    "|     | 강우 | 맑음 |\n",
    "|-----|-----|-----|\n",
    "| 승리 |  3  |  2  |\n",
    "| 패배 |  1  |  6  |\n",
    "\n",
    "\n",
    "* 오늘 비가 오고 있는데, 이 경우 승리할 확률을 구하면,\n",
    "* $P(A=승리|B=비) = \\frac{P(B|A) P(A)}{P(B)} = \\frac{(3/5) (5/12)}{(4/12)} = 3/4 =0.75$\n",
    "* 즉, 사전확률prior probability 5/12, 가능도likelihood 3/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 4: Naive Bayesian 추론\n",
    "\n",
    "A=m, B=q이면, C가 1인지 0인지 추론해보자.\n",
    "* C가 1인 확률: \n",
    "    * $Pr(C=1) \\times \\prod_{j=1}^2\\ Pr(A_j=a_j|C=1)$\n",
    "    * Pr(C=1) x ( Pr(A=m | C=1) x Pr(B=q | C=1) ) = 1/2 x 2/5 x 2/5 = 2/25\n",
    "\n",
    "* C가 0인 확률:\n",
    "    * $Pr(C=0) \\times \\prod_{j=1}^2\\ Pr(A_j=a_j|C=0)$\n",
    "    * Pr(C=0) x ( Pr(A=m | C=0) x Pr(B=q | C=0) ) = 1/2 x 1/5 x 2/5 = 1/25\n",
    "\n",
    "* argmax(2/25,1/25)를 구하면 첫 번째, 즉 C=1로 추론하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 데이터\n",
    "\n",
    "numpy 구조배열 structured array 또는 record array는 C언어의 'struct'과 비슷한 구조화된 배열\n",
    "이런 구조는 Pandas를 사용하기도 한다.\n",
    "\n",
    "데이터는 **튜플리스트**로 만들어 준다.\n",
    "컬럼명과 데이터타입의 메타데이터를 설정해서 데이터를 읽을 수 있다.\n",
    "* 속성은 'A', 'B', 'C'로 명명한다.\n",
    "* 데이터형 dtype의 'U'는 유니코드 문자열, 뒤 숫자는 자릿수를 의미한다.\n",
    "i는 정수, 뒤 숫자는 8비트, 'i1'은 8비트 정수를 의미한다.\n",
    "'a1'은 문자열 1자리로 정의한다.\n",
    "\n",
    "```python\n",
    "np.array([('m', 'b', 1), ... ('m', 'b', 0)], dtype=[('A','a1'),('B','a1'),('C','a1')])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "_x = np.array([\n",
    "        ('m', 'b', 1),\n",
    "        ('m', 's', 1),\n",
    "        ('g', 'q', 1),\n",
    "        ('h', 's', 1),\n",
    "        ('g', 'q', 1),\n",
    "        ('g', 'q', 0),\n",
    "        ('g', 's', 0),\n",
    "        ('h', 'b', 0),\n",
    "        ('h', 'q', 0),\n",
    "        ('m', 'b', 0)],\n",
    "        dtype=[('A', 'U1'), ('B', 'U1'), ('C', 'i1')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 조건에 따른 조회\n",
    "\n",
    "numpy의 구조배열은 속성명(메타데이터)으로 데이터를 읽을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy 구조배열이므로, **컬럼명 인덱스로 선택**하여 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m', 'm', 'g', 'h', 'g', 'g', 'g', 'h', 'h', 'm'], dtype='<U1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "앞은 컬럼명, 뒤 [1:5]는 시작 2번째 ~ 끝 5번째까지 행을 선택하여 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['s', 'q', 's', 'q'], dtype='<U1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x['B'][1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "조건에 맞는 **모든 행**을 읽을 수 있다.\n",
    "```_x['A'=='m']```이라고 하면 안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('m', 'b', 1), ('m', 's', 1), ('m', 'b', 0)],\n",
       "      dtype=[('A', '<U1'), ('B', '<U1'), ('C', 'i1')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x[_x['A']=='m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**특정 컬럼**에 대해 조건에 맞는 경우만을 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m', 'm', 'g', 'h', 'g'], dtype='<U1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x['A'][_x['C']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "np.count_nonzero() 함수를 사용해서 조건에 맞는 개수를 계산할 수 있다.\n",
    "C가 1인 경우의 A컬럼에 대해 m의 개수를 세면 2가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(_x['A'][_x['C']==1] == 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1) 사후확률 post_c1 (c=1)\n",
    "\n",
    "A=m이고 B=q일 경우, Pr(C=1)를 구해보자\n",
    "\n",
    "확률은 딕셔너리 구조를 활용해서 풀어보자.\n",
    "딕셔너리는 키와 값을 저장하는 구조이다.\n",
    "확률은 전체 개수에서 고유키가 몇 개 발생했는지 계산하기로 하자.\n",
    "\n",
    "c가 1일 경우, A=m이고 B=q일 확률은 0.08이다. 5/10 x 2/5 x 2/5 = 2/25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1-1) 사전확률 Pr(c=1)\n",
    "\n",
    "프로그램으로 확률을 계산하려면 조금 복잡하다.\n",
    "어떤 키 key가 있는지 찾아야 하고, 그 키가 전체에 몇 개 있는지 계산해야 한다.\n",
    "세째 컬럼을 보자. \n",
    "전체 10개 사례 가운데 '1'은 5개이다.\n",
    "확률은 $\\frac{5}{10}=0.5$가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 키를 세어보자.\n",
    "모든 사례에 대하여 키와 빈도를 세어 ```defaultdict(int)```로 사전확률을 저장한다.\n",
    "처음에는 딕셔너리가 **아무 것도 없이 깨끗하게 비어있게 되고, 여기에 키를 추가하려면, defaultdict으로 선언**하고 사용해야 한다.\n",
    "```int```로 선언한 이유는, 빈도가 정수이므로 그렇다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "prior_kc=collections.defaultdict(int)\n",
    "for item in _x['C']:\n",
    "    prior_kc[item]+=1 # ok to add (key, value) to defaultdict. NOT ok if not defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior key counts computed: defaultdict(<class 'int'>, {1: 5, 0: 5})\n"
     ]
    }
   ],
   "source": [
    "print ('prior key counts computed: {}'.format(prior_kc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```defaultdict(int)```에 저장된 키, 빈도로 부터 확률을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_c: {1: 0.5, 0: 0.5}\n"
     ]
    }
   ],
   "source": [
    "allFreq=sum(prior_kc.values())\n",
    "prior_c=dict()\n",
    "for k,v in prior_kc.items():\n",
    "    prior_c[k]=float(v)/allFreq\n",
    "print (\"prior_c: {}\".format(prior_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1-2) 가능도 Pr(A=m | c=1) -> 2/5\n",
    "\n",
    "c=1인 경우, A=m인 우도를 계산해보자.\n",
    "c=1은 5개, 5개 가운데 A=m인 경우가 2회 이므로, 확률은 2/5가 된다. -> 2/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kc_a_c1 key counts computed: {} defaultdict(<class 'int'>, {'m': 2, 'g': 2, 'h': 1})\n"
     ]
    }
   ],
   "source": [
    "aLikelihood_c1=_x['A'][_x['C']==1]\n",
    "kc_a_c1=collections.defaultdict(int)\n",
    "for item in aLikelihood_c1:\n",
    "    kc_a_c1[item]+=1\n",
    "print ('kc_a_c1 key counts computed: {}',format(kc_a_c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_a_c1: {'m': 0.4, 'g': 0.4, 'h': 0.2}\n"
     ]
    }
   ],
   "source": [
    "allFreq=len(aLikelihood_c1)\n",
    "prob_a_c1=dict()\n",
    "for k,v in kc_a_c1.items():\n",
    "    prob_a_c1[k]=float(v)/allFreq\n",
    "print (\"prob_a_c1: {}\".format(prob_a_c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1-3) 가능도 Pr(B=q | c=1) -> 2/5\n",
    "\n",
    "c=1인 경우, B=q인 우도를 계산해보자.\n",
    "c=1은 5개, 5개 가운데 B=q인 경우가 2회 이므로, 확률은 2/5가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kc_b_c1 key counts computed: {} defaultdict(<class 'int'>, {'b': 1, 's': 2, 'q': 2})\n"
     ]
    }
   ],
   "source": [
    "bLikelihood_c1=_x['B'][_x['C']==1]\n",
    "kc_b_c1=collections.defaultdict(int)\n",
    "for item in bLikelihood_c1:\n",
    "    kc_b_c1[item]+=1\n",
    "print ('kc_b_c1 key counts computed: {}',format(kc_b_c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_b_c1: {'b': 0.2, 's': 0.4, 'q': 0.4}\n"
     ]
    }
   ],
   "source": [
    "allFreq=len(bLikelihood_c1)\n",
    "prob_b_c1=dict()\n",
    "for k,v in kc_b_c1.items():\n",
    "    prob_b_c1[k]=float(v)/allFreq\n",
    "print (\"prob_b_c1: {}\".format(prob_b_c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1-4) 사후확률 post_c1 (c=1) -> 0.08 (2/25 = 5/10 * 2/5 * 2/5)\n",
    "\n",
    "사후확률은 앞서 계산한 사전확률 및 우도를 곱해서 계산한다. 0.5 * 0.4 * 0.4 = 0.08\n",
    "* 사전확률 prior_c: {1: 0.5, 0: 0.5}에서 0.5,\n",
    "* A의 우도 prob_a_c1: {'m': 0.4, 'g': 0.4, 'h': 0.2}에서 0.4,\n",
    "* B의 우도 prob_b_c1: {'b': 0.2, 's': 0.4, 'q': 0.4}에서 0.4,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_c: {1: 0.5, 0: 0.5}\n"
     ]
    }
   ],
   "source": [
    "print (\"prior_c: {}\".format(prior_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_a_c1: {'m': 0.4, 'g': 0.4, 'h': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print (\"prob_a_c1: {}\".format(prob_a_c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_b_c1: {'b': 0.2, 's': 0.4, 'q': 0.4}\n"
     ]
    }
   ],
   "source": [
    "print (\"prob_b_c1: {}\".format(prob_b_c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 계산결과를 넣어서 사후확률을 계산해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior computed if c==1: 0.080\n"
     ]
    }
   ],
   "source": [
    "post_c1=prior_c[1]*prob_a_c1['m']*prob_b_c1['q']\n",
    "print (\"posterior computed if c==1: {:.3f}\".format(post_c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2) 사후확률 post_c0 (c=0)\n",
    "\n",
    "이번에는 A=m이고 B=q일 경우, Pr(C=0)를 구해보자\n",
    "\n",
    "앞서 확률은 딕셔너리 구조를 활용해서 풀어보았다. 여기서는 개수만을 세어서 계산해보자.\n",
    "\n",
    "c가 0일 경우, A=m이고 B=q일 확률은 0.04이다. 5/10 x 1/5 x 2/5 = 1/25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "np.count_nonzero() 함수는 조건에 맞는 요소의 개수를 계산한다. 2차원 배열은 axis=0이면 컬럼별, axis=1 행별로 계산을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_c0 = np.count_nonzero(_x['C']==0)/_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "c=0일 경우 A=m의 개수는 1, c=0인 개수는 5이다. 이를 나누면 0.2이다. 아래식과 같이 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_am_c0=np.count_nonzero(_x['A'][_x['C']==0] == 'm')/np.count_nonzero(_x['C']==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "c=0일 경우 B=q의 개수는 2, c=0인 개수는 5이다. 이를 나누면 0.4이다. 아래식과 같이 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_bq_c0=np.count_nonzero(_x['B'][_x['C']==0] == 'q')/np.count_nonzero(_x['C']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'post_cf:0.040'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_c0 = prior_c0 * prob_am_c0 * prob_bq_c0\n",
    "f\"post_cf:{post_c0:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### lambda 함수를 이용해보기\n",
    "\n",
    "이번에는 lambda함수를 정의해서 간단히 해보자.\n",
    "\n",
    "**set은 중복이 없이 저장한다는 특성**을 이용해서 키를 구한다.\n",
    "그리고 **리스트의 특정 요소가 몇 개인지 세는 count()** 함수를 이용해서 **딕셔너리**로 출력한다.\n",
    "짧은 코드이지만, 간단 명료하게 기능을 다하고 있다.\n",
    "\n",
    "```python\n",
    "getProb=lambda x: dict((i,x.count(i)/float(len(x))) for i in set(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 확률은 계산하자.\n",
    "아래 코드에서 반복문에서 set를 이용해서 키를 추출하고, ```리스트.count(i)/float(len(리스트))```로 개수를 계산한다. set와 리스트의 특징을 잘 활용한 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_0: 0.5\n",
      "prior_1: 0.5\n"
     ]
    }
   ],
   "source": [
    "c=_x['C'].tolist()\n",
    "for i in set(c):\n",
    "    print(\"prior_{}: {}\".format(i, c.count(i)/float(len(c))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "위 코드를 lambda로 변경해서 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior: {0: 0.5, 1: 0.5}\n"
     ]
    }
   ],
   "source": [
    "# ref: DecisionTree.getProb()\n",
    "getProb=lambda x: dict((i,x.count(i)/float(len(x))) for i in set(x))\n",
    "print (\"prior: {}\".format(getProb(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_b_c0: {'h': 0.4, 'm': 0.2, 'g': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# Pr(A=m | c=0) -> 1/5\n",
    "a=_x[_x['C']==0]['A'].tolist()\n",
    "prob_a_c0=getProb(a)\n",
    "print (\"prob_b_c0: {}\".format(prob_a_c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_b_c0: {'s': 0.2, 'b': 0.4, 'q': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# Pr(B=q | c=0) -> 2/5\n",
    "b=_x[_x['C']==0]['B'].tolist()\n",
    "prob_b_c0=getProb(b)\n",
    "print (\"prob_b_c0: {}\".format(prob_b_c0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3) 의사결정\n",
    "\n",
    "확률이 높은 true로 결정한다.\n",
    "argmax()는 큰 값의 인덱스를 출력한다.\n",
    "즉, post_ct = 0.08, post_cf=0.04이므로 첫번째 인덱스인 0이 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([post_c1,post_c0]).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.6 이항 베이지안\n",
    "\n",
    "**이항모델 Binomial Bayesian**은 다항모델의 한 종류이다. 이항분포는 사건이 이진적일 경우에 적용하게 된다. 동전은 앞, 뒤면 가운데 하나가 발생할 수 있다. 앞면의 확률이 p이면, 뒷면 확률은 1-p이다.\n",
    "\n",
    "발생빈도가 아니라, 발생했는지 안했는지 이진적으로 측정한다. 동전을 1회 던지는 경우를 예로 들 수 있다. 앞 면이면 1, 뒷 면이면 0으로 확률을 계산한다.\n",
    "\n",
    "베이지안 확률에 따르면:\n",
    "$p(\\theta|D) = \\frac{p(D|\\theta) p(\\theta)}{p(D)}$\n",
    "\n",
    "$\\theta$는 가설로서, 어떤 확률이 된다. D는 증거 또는 데이터를 말한다.\n",
    "\n",
    "* 사전확률 $p(\\theta)$이란 증거 D를 감안하지 않고 사전에 $\\theta$에 대한 믿음의 강도을 말한다.\n",
    "* 사후확률 $p(\\theta|D)$ 증거 D를 고려하고 가지게 되는 믿음의 강도. 예를 들어, 동전을 10번 던져서 5회 나왔다는 것을 보고 나서, 확률이 $\\theta$라고 믿게 되는 확률을 말한다.\n",
    "* 가능도 $p(D|\\theta)$란 동전이 $\\theta$의 확률일 경우, 예를 들어, 10회 던져서 몇 번이나 앞, 뒤면이 나오는지를 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규분포와 이항분포의 분포를 displot() 그래프로 그려보자.\n",
    "binomial()은 n시도에서, p=성공확률로 무작위 수를 생성한다.\n",
    "normal()은 loc 평균, scale 분산으로 무작위 수를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.kdeplot(random.normal(loc=50, scale=5, size=1000), label='normal')\n",
    "sns.kdeplot(random.binomial(100, p=0.5, size=1000), label='binomial')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전확률\n",
    "\n",
    "사전확률 $p(\\theta)$는 베타분포를 따른다고 하자, $\\theta \\sim Beta(\\alpha, \\beta)$\n",
    "베타분포를 따르는 경우, $\\alpha$, $\\beta$에 따라 모양이 결정된다.\n",
    "두 값을 1, 1이라고 하고, 100회 무작위 샘플하면 평균값을 사전확률로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5179522337142154"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.beta(1,1,100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(random.beta(a=1, b=1, size=1000), label='binomial')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가능도 \n",
    "\n",
    "이항분포 PMF Probability Mass Function은 성공(p확률) k회, 실패(1-p확률) n-k회인 경우: \n",
    "\n",
    "$$\n",
    "f(k;n,p) = P(X = k) = \\binom{n}{k}p^k(1-p)^{n-k}\n",
    "$$\n",
    "\n",
    "choose n for k는 가능한 경우의 수를 의미한다. 순서를 무시해서 계산하면,\n",
    "\n",
    "p=0.5인 이항분포에서의 확률은 $P(D|\\theta) = 0.5^{30} \\cdot (1−0.5)^{70}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015625\n"
     ]
    }
   ],
   "source": [
    "# 6회에서 앞 면이 0,1,2,3,4,5,6 나올 확률. 단 동전이 biased되어서 앞면 확률은 0.3.-> 0.5\n",
    "# 확률을 구해보면:\n",
    "from scipy import special\n",
    "n=6\n",
    "k=0\n",
    "p=0.5\n",
    "# comb(6,0)는 exact연산.\n",
    "print (special.comb(6, k, exact=True)*(p**k)*( (1-p)**(n-k) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(X = 0 heads)= 0.01562\n",
      "Pr(X = 1 heads)= 0.09375\n",
      "Pr(X = 2 heads)= 0.23438\n",
      "Pr(X = 3 heads)= 0.31250\n",
      "Pr(X = 4 heads)= 0.23438\n",
      "Pr(X = 5 heads)= 0.09375\n",
      "Pr(X = 6 heads)= 0.01562\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print (\"Pr(X = {} heads)= {:.5f}\".format(i, special.comb(6, i, exact=True)*(p**i)*( (1-p)**(n-i) ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01563\n",
      "0.09375\n",
      "0.23438\n",
      "0.31250\n",
      "0.23438\n",
      "0.09375\n",
      "0.01563\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "for i in range(7):\n",
    "    print (\"{:.5f}\".format(stats.binom.pmf(i,6,0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사후 확률\n",
    "\n",
    "베이지안 사후확률은:\n",
    "$p(\\theta | k,n) = \\frac{\\displaystyle P(k,n|\\theta) P(\\theta)}{\\displaystyle P(k,n)}$\n",
    "\n",
    "이식에,\n",
    "* 사전확률은 베타분포,\n",
    "* 가능도는 앞서 계산한 $\\theta^k(1-\\theta)^{n-k}$,\n",
    "* 그리고 분모는 생략하여 정리하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러면 아래 식으로 계산된다.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(C_k \\vert k,n)\n",
    "    & \\varpropto P(k,n|\\theta) P(\\theta)\\\\\n",
    "    & \\varpropto \\theta^k(1-\\theta)^{n-k}\\\n",
    "        \\cdot \\theta^{\\alpha - 1}(1-\\theta)^{\\beta -1}\\\\\n",
    "    & = \\theta^{k+\\alpha-1}(1-\\theta)^{n-k+\\beta-1}\\\\\n",
    "    & = Beta(\\theta \\vert k+\\alpha, n-k+\\beta)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n",
    "사전확률 $P(\\theta)$이 베타분포를 따르면 $\\theta \\sim Beta(\\alpha, \\beta)$,\n",
    "사후확률도 베타분포를 따르게 된다 $\\theta \\sim Beta(k+\\alpha, n-k+\\beta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전, 사후확률의 확률분포를 그려보자.\n",
    "* 앞서 사전확률은 $\\theta \\sim Beta(\\alpha=1, \\beta=1)$\n",
    "* n=100회 던져서 k=70회가 앞면이 나왔다고 하면 가능도는 $\\theta \\sim Beta(\\alpha=70,\\beta=100-70)=Beta(\\alpha=70, \\beta=30)$\n",
    "* 앞서 사후확률은 $\\theta \\sim Beta(\\alpha=70+1, \\beta=100-70+1)=Beta(\\alpha=71, \\beta=31)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(random.beta(a=1, b=1, size=1000), label='beta') #prior a=1, b=1\n",
    "sns.kdeplot(random.beta(a=70, b=30, size=1000), label='beta') #likelihood a=70, b=100-70 (n=100, k=30)\n",
    "sns.kdeplot(random.beta(a=71, b=31, size=1000), label='beta') #posterior a=70+1, b=100-70+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림에서 보듯이, 사후확률의 분포는 오른쪽으로 움직이고 폭이 더욱 좁아졌다.\n",
    "이는 100에서 70회가 앞면이 나왔다는 사실에 더욱 확신이 증가했다는 의미이다.\n",
    "평균은0.696 표준편차는 0.045, 그러니까 동전은 69.6%는 앞면이 나올 것이, 표준편차는 불과 0.045라는 의미이다.\n",
    "\n",
    "이와 같이 가능도의 분포가 베타분포이면, 컬레확률로 사전확률과 사후확률이 베타분포를 따르고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean: 0.696 std:0.045'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "a=71 #posterior a=70+1, b=100-70+1 (n=100, k=30)\n",
    "b=31\n",
    "mu=a/(a+b)\n",
    "std=math.sqrt(a*b/(math.pow(a+b,2)*(a+b+1)))\n",
    "f\"mean: {mu:.3f} std:{std:.3f}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn\n",
    "\n",
    "\"Seoul\", \"Jongro\", \"Gangnam\"은 한국, \"Sydney\",\"NY\"는 외국이라고 이진분류하는 문제이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "city_list = [\"Seoul\", \"Jongro\", \"Sydney\", \"Gangnam\", \"NY\"]\n",
    "feature1 = [1, 0, 0, 0, 0]\n",
    "feature2 = [0, 1, 0, 1, 0]\n",
    "feature3 = [0, 0, 1, 0, 0]\n",
    "feature4 = [0, 0, 0, 1, 0]\n",
    "feature5 = [0, 0, 1, 0, 1]\n",
    "feature6 = [1, 1, 0, 0, 0]\n",
    "labels = [1, 1, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy 배열로 6건 x 속성 5로 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData = np.array([feature1, feature2, feature3, feature4, feature5, feature6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```BernoulliNB(*, alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)```\n",
    "* ```alpha```는 스무딩을 할 것인지 기본값은 1.0, 스무딩하지 않는 경우 0\n",
    "* ```binarize```는 이분화를 할 경우의 임계치를 말한다. 기본 값은 0.0, 이미 이분화가 되어 있는 경우에는 None이라고 해준다.\n",
    "* ```fit_prior```는 사전확률을 학습할 것인지, 기본 값은 true, false로 하면 균등분포가 사용된다.\n",
    "* ```class_prior```는 클래스에 대한 사전확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trainData, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델링에 사용되었던 데이터를 그대로 예측해보자.\n",
    "```labels = [1, 1, 0, 1, 0, 1]```과 동일한 결과를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 한국만, 또는 한국과 외국이 혼합된 경우를 예측해보자.\n",
    "* (1) Sydney, Gangnam, NY이 1로 한국, 외국이 혼합된 [0, 0, 1, 1, 1] 경우,\n",
    "* (2) Seoul, Gangnam이 1로 한국만 포함된 [1, 0, 0, 1, 0] 경우\n",
    "* (3) Seoul, Jongro, Sydney 한국과 외국이 혼합된 [1, 1, 1, 1, 0] 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData=np.array([[0, 0, 1, 1, 1], [1, 0, 0, 1, 0], [1, 1, 1, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측하면 (1)의 경우는 0 (외국), (2)는 1 (한국), (3)은 1 (한국)으로 예측된다.\n",
    "(1)은 외국이 한국보다 많아서, (3)은 한국이 많아서 설정된 가중치에 따라 추론된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확성은 trainData에 대해 측정한다. trainData는 label이 붙여져 있고, 반면에 testData는 label이 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(trainData,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testData에 대해 정확성을 측정하려면, label 데이터를 넣어주어야 한다.\n",
    "이런 작업, 각 사례에 대해 한국인지 외국인지 판정하는 작업이 필요하다.\n",
    "대량 데이터를 훈련하기 위해서는, 지도기계학습에서는 필수적으로 해야하고 상당한 시간과 노력이 필요할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(testData, [0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_proba()는 확률추정치를 출력한다.\n",
    "각 feature에 대한 가중치 역할을 하게 되고, 앞서 한국, 외국이 혼합된 사례의 추론의 이유이기도 하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09194098, 0.90805902],\n",
       "       [0.03264813, 0.96735187],\n",
       "       [0.8200225 , 0.1799775 ],\n",
       "       [0.09194098, 0.90805902],\n",
       "       [0.95795007, 0.04204993],\n",
       "       [0.03264813, 0.96735187]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr=clf.predict_proba(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 2), (3, 5))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.shape, testData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제: Sklearn make_classification으로 생성된 데이터에 대해 이진 베이지안 모델\n",
    "\n",
    "Sklearn의 make_classification() 함수는 분류에 쓰일 수 있는 데이터를 생성해준다.\n",
    "\n",
    "```python\n",
    "sklearn.datasets.make_classification(n_samples=100, n_features=20, *, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "```\n",
    "* n_samples: 표본 데이터의 수\n",
    "* n_features: 독립 변수의 수\n",
    "* n_informative: 독립 변수 중 종속 변수와 상관 관계가 있는 성분의 수\n",
    "* n_redundant: 독립 변수 중 다른 독립 변수의 선형 조합으로 나타나는 성분의 수\n",
    "* n_repeated : 독립 변수 중 단순 중복된 성분의 수\n",
    "* n_classes : 종속 변수의 클래스 수\n",
    "* n_clusters_per_class : 클래스 당 클러스터의 수\n",
    "* weights : 각 클래스에 할당된 표본 수\n",
    "* random_state : 난수 발생 시드\n",
    "\n",
    "단, n_informative + n_redundant + n_repeated <= n_features이어야 한다.\n",
    "\n",
    "Sklearn으로 이진 베이지안 모델링을 해보자.\n",
    "* (1) X, Y 데이터를 생성\n",
    "* (2) X의 평균과 표준편차 계산해서 출력\n",
    "* (3) 그래프 작성\n",
    "    * scatter() 함수에 c=Y 옵션을 넣으면, Y의 값에 대해 다른 색으로 표시할 수 있다.\n",
    "* (4) 훈련데이터, 테스트데이터 3:1로 분리\n",
    "* (5) 훈련데이터에 대하여 BernoulliNB 모델링\n",
    "    * X데이터는 연속 값이다. binarize=0.0으로 설정하여 이진수로 모델링한다.\n",
    "* (6) 테스트데이터에 대하여 예측값을 출력\n",
    "    * 예측이 맞는지 실제값 Y와 비교해보자.\n",
    "* (7) 테스트데이터에 대하여 예측과 실제의 정확성 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터\n",
    "\n",
    "2개의 속성을 적당한 상관관계를 가진 값으로 설정하여 100개의 데이터를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, Y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96255227, -0.68490584],\n",
       "       [-0.11077626,  2.22517758],\n",
       "       [-0.7549931 , -2.44458057],\n",
       "       [ 1.73518271, -1.19390865],\n",
       "       [ 1.15665994, -0.79632483]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평균, 표준편차\n",
    "\n",
    "X는 numpy array이다. 평균과 표준편차를 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01530284994603548, 1.2082428010152255)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(), X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프\n",
    "\n",
    "Y값에 따라 다른 색으로 그리기 위해서는 ```c=Y```라고 설정해준다.\n",
    "```s```는 마커의 크기, 제곱으로 표현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], marker='o', c=Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할\n",
    "\n",
    "데이터는 연속 값이다. 이 경우 ```binarize``` 설정을 해서, 임계치를 0.0을 사용해서 이분화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB(binarize=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측\n",
    "\n",
    "25개 가운데 3개 오류가 발생하였다. 정확성은 1 - 3/25 = 0.88이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, array([2.2040367, 0.8148905])),\n",
       " (0, 0, array([-0.21547427, -1.98209421])),\n",
       " (0, 1, array([-0.01922866,  1.2834575 ])),\n",
       " (1, 1, array([ 0.4092987 , -0.54993738])),\n",
       " (0, 0, array([-0.55004677, -1.62371851])),\n",
       " (0, 0, array([-0.84085852,  1.76930832])),\n",
       " (1, 1, array([1.78596659, 0.63646744])),\n",
       " (0, 0, array([-0.55426677,  1.47174936])),\n",
       " (0, 0, array([-0.17316481, -1.83363081])),\n",
       " (0, 0, array([-1.06011104,  0.3012968 ])),\n",
       " (1, 1, array([ 0.39334257, -0.11148504])),\n",
       " (1, 0, array([ 0.19364671, -2.16819498])),\n",
       " (0, 0, array([-1.57085785,  0.53746024])),\n",
       " (0, 0, array([-0.3445515 , -1.33665725])),\n",
       " (0, 0, array([-0.44776176,  1.44036882])),\n",
       " (0, 1, array([-0.07054296, -0.30149589])),\n",
       " (1, 1, array([1.10455119, 0.52331746])),\n",
       " (0, 0, array([-0.63375443,  0.92610748])),\n",
       " (1, 1, array([0.86483949, 0.69694086])),\n",
       " (0, 0, array([-0.32608105,  2.24049215])),\n",
       " (0, 0, array([-0.57238458, -1.21823668])),\n",
       " (0, 0, array([-2.21538324, -0.07494476])),\n",
       " (0, 0, array([-0.00970267,  1.76244478])),\n",
       " (0, 0, array([-1.76420424, -0.39463993])),\n",
       " (0, 0, array([-0.7394483 , -1.01759153]))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(bnb.predict(X_test),Y_test, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이진 값을 넣어서 예측값을 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.predict([[1,1], [1,-1], [-1,1], [-1,-1], [0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 정확성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 정규분포 베이지안\n",
    "\n",
    "**정규모델 Normal Bayesian**은 아래 몸무게, 키, 발크기로 성별을 구분하는 문제이고, 정규분포를 사용한다\n",
    "\n",
    "height=6ft, weight=130lbs, foot size=8inches 경우 성별을 추론해보자.\n",
    "키, 몸무게와 같은 연속적 변수이고, 분포 distribution에 따라 무작위로 발생한다.\n",
    "\n",
    "* source: http://en.wikipedia.org/wiki/Naive_Bayes_classifier\n",
    "\n",
    "| sex\t | height(feet) | weight(lbs) | foot size(inches) |\n",
    "|--------|-----:|----:|---:|\n",
    "| male   | 6    | 180 | 12 |\n",
    "| male   | 5.92 | 190 | 11 |\n",
    "| male   | 5.58 | 170 | 12 |\n",
    "| male   | 5.92 | 165 | 10 |\n",
    "| female | 5    | 100 |  6 |\n",
    "| female | 5.5  | 150 |  8 |\n",
    "| female | 5.42 | 130 |  7 |\n",
    "| female | 5.75 | 150 |  9 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터 준비\n",
    "\n",
    "numpy 구조 배열로 데이터를 생성하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "_hwf = np.array([\n",
    "        ('male',6,180,12),\n",
    "        ('male',5.92,190,11),\n",
    "        ('male',5.58,170,12),\n",
    "        ('male',5.92,165,10),\n",
    "        ('female',5,100,6),\n",
    "        ('female',5.5,150,8),\n",
    "        ('female',5.42,130,7),\n",
    "        ('female',5.75,150,9)],\n",
    "        dtype=[('sex', 'U6'), ('height', 'f4'), ('weight', 'i4'), ('foot', 'i4')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 사전확률\n",
    "\n",
    "사전확률은 전체 개수를 'male', 'female' 개수로 나눈 값이다.\n",
    "위 데이터에서 남녀의 확률 (즉 4/8), 0.5이다.\n",
    "또는 P(M), P(F)은 인구통계에서 보면 남녀 모두 0.5라고 봐도 무방하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_m=0.5\n",
    "# p(height|M) ~ N(6,남자키평균,남자키표준편차), 즉 N(6,5.855,0.187)\n",
    "pr_f=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prior_m: 0.5, prior_f: 0.5'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_m = np.count_nonzero(_hwf['sex']=='male')/_hwf.shape[0]\n",
    "prior_f = np.count_nonzero(_hwf['sex']=='female')/_hwf.shape[0]\n",
    "f\"prior_m: {prior_m}, prior_f: {prior_f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 가능도\n",
    "\n",
    "확률을 구하기 위해서는 분포를 추정해야 한다. 남녀의 키, 몸무게, 발길이 정규분포로 볼 수 있다.\n",
    "정규분포 확률을 계산하기 위해 평균, 표준편차이 필요하다.\n",
    "\n",
    "#### (3-1) 정규분포 확률계산에 필요한 평균, 표준편차 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pdf=pd.DataFrame(_hwf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>foot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>5.4175</td>\n",
       "      <td>132.50</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>5.8550</td>\n",
       "      <td>176.25</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        height  weight   foot\n",
       "sex                          \n",
       "female  5.4175  132.50   7.50\n",
       "male    5.8550  176.25  11.25"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby('sex').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>foot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.311809</td>\n",
       "      <td>23.629078</td>\n",
       "      <td>1.290994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.187172</td>\n",
       "      <td>11.086779</td>\n",
       "      <td>0.957427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          height     weight      foot\n",
       "sex                                  \n",
       "female  0.311809  23.629078  1.290994\n",
       "male    0.187172  11.086779  0.957427"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby('sex').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3.2) 확률 계산\n",
    "\n",
    "남자의 경우 키가 6 feet일 확률 Pr(Height=6|Male)을 계산해보자.\n",
    "이런 연속변수의 확률은 normpdf를 계산해서 구한다.\n",
    "정규분포의 확률밀도함수 (pdf, Probability Dense Function)는:\n",
    "\n",
    "$\\frac{\\displaystyle 1}{\\displaystyle \\sigma \\sqrt{2\\pi}}\n",
    "e^{-\\frac{\\displaystyle 1}{\\displaystyle 2}(\\frac{\\displaystyle x-\\mu}{\\displaystyle \\sigma})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 함수로 만들기\n",
    "def normpdf(x, mu=0, std=1):\n",
    "    n = float(x-mu) / abs(std)\n",
    "    g = np.exp(-n*n/2) / (abs(std) * np.sqrt(2*np.pi))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pr(Height|Male): 1.5789, mean_h_m: 5.8550, std_h_m: 0.1872'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_h_m=_hwf['height'][_hwf['sex']=='male'].mean()\n",
    "std_h_m=_hwf['height'][_hwf['sex']=='male'].std(ddof=1)\n",
    "pr_h_m=normpdf(6, mean_h_m, std_h_m) #1.5788829647561371, 확률이 아니라 확률분포값\n",
    "f\"Pr(Height|Male): {pr_h_m:.4f}, mean_h_m: {mean_h_m:.4f}, std_h_m: {std_h_m:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pr_h_m: 0.0000, mean_h_m: 11.2500, std_h_m: 0.9574'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_f_m=_hwf['foot'][_hwf['sex']=='male'].mean() #11.25\n",
    "std_f_m=_hwf['foot'][_hwf['sex']=='male'].std(ddof=1) #0.957\n",
    "pr_f_m=normpdf(8, std_f_m, std_f_m) #0.0013050759944537563\n",
    "f\"pr_h_m: {pr_f_m:.4f}, mean_h_m: {mean_f_m:.4f}, std_h_m: {std_f_m:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pr_w_m: 0.00000599, mean_w_m: 176.2500, std_w_m: 11.0868'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_w_m=_hwf['weight'][_hwf['sex']=='male'].mean() #176.25\n",
    "std_w_m=_hwf['weight'][_hwf['sex']=='male'].std(ddof=1) #11.0868\n",
    "pr_w_m=normpdf(130, mean_w_m, std_w_m) #5.9869297985549439e-06\n",
    "f\"pr_w_m: {pr_w_m:.8f}, mean_w_m: {mean_w_m:.4f}, std_w_m: {std_w_m:.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pr(Height|Female): 0.2235, mean_h_f: 5.4175, std_h_f: 0.3118'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_h_f=_hwf['height'][_hwf['sex']=='female'].mean() #5.4175\n",
    "std_h_f=_hwf['height'][_hwf['sex']=='female'].std(ddof=1) #0.311809\n",
    "pr_h_f=normpdf(6,mean_h_f,std_h_f) #0.2235\n",
    "f\"Pr(Height|Female): {pr_h_f:.4f}, mean_h_f: {mean_h_f:.4f}, std_h_f: {std_h_f:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pr(Foot|Female): 0.2867, mean_f_f: 7.5000, std_f_f: 1.2910'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_f_f=_hwf['foot'][_hwf['sex']=='female'].mean() #7.5\n",
    "std_f_f=_hwf['foot'][_hwf['sex']=='female'].std(ddof=1) #1.291\n",
    "pr_f_f=normpdf(8,mean_f_f,std_f_f) #0.2867\n",
    "f\"Pr(Foot|Female): {pr_f_f:.4f}, mean_f_f: {mean_f_f:.4f}, std_f_f: {std_f_f:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pr(Weight|Female): 0.0168, mean_w_f: 132.5000, std_w_f: 23.6291'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_w_f=_hwf['weight'][_hwf['sex']=='female'].mean() #132.5\n",
    "std_w_f=_hwf['weight'][_hwf['sex']=='female'].std(ddof=1) #23.629\n",
    "pr_w_f=normpdf(130,mean_w_f,std_w_f) #0.0168\n",
    "f\"Pr(Weight|Female): {pr_w_f:.4f}, mean_w_f: {mean_w_f:.4f}, std_w_f: {std_w_f:.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 사후확률\n",
    "\n",
    "$\n",
    "posterior(M)=\\frac{P(M)\\ p(height|M)\\ p(weight|M)\\ p(foot size|M)}{evidence}\\\\\n",
    "posterior(F)=\\frac{P(F)\\ p(height|F)\\ p(weight|F)\\ p(foot size|F)}{evidence}\n",
    "$\n",
    "\n",
    "위 식에서 Evidence는 이 값은 상수 값이므로, 사후확률 계산에서 제외한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사후확률 male: 0.00000001, 사후확률 female: 0.00053779'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_m=pr_m * pr_h_m * pr_f_m * pr_w_m #6.1682207841818461e-09\n",
    "post_f=pr_f*pr_h_f*pr_w_f*pr_f_f #0.00053778969521895402\n",
    "f\"사후확률 male: {post_m:.8f}, 사후확률 female: {post_f:.8f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (5) 추론\n",
    "\n",
    "4. argmax를 구하면 1, 즉 post_f일 확률이 높으므로, 여성이라고 구분함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([post_m,post_f]) #1 즉 female로 예측."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Sklearn\n",
    "\n",
    "```python\n",
    "GaussianNB(*, priors=None, var_smoothing=1e-09)\n",
    "```\n",
    "* 사전확률\n",
    "* smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=_hwf[:][['height', 'weight', 'foot']]\n",
    "y=_hwf[:]['sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "튜플리스트를 2차원 리스트로 변환해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [list(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6.0, 180, 12],\n",
       " [5.92, 190, 11],\n",
       " [5.58, 170, 12],\n",
       " [5.92, 165, 10],\n",
       " [5.0, 100, 6],\n",
       " [5.5, 150, 8],\n",
       " [5.42, 130, 7],\n",
       " [5.75, 150, 9]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'male', 'male', 'male', 'female', 'female', 'female',\n",
       "       'female'], dtype='<U6')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X, y)\n",
    "Y_gnb_score = gnb.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01445408e-06, 9.99998986e-01],\n",
       "       [1.68038573e-05, 9.99983196e-01],\n",
       "       [7.74236193e-05, 9.99922576e-01],\n",
       "       [5.73512178e-03, 9.94264878e-01],\n",
       "       [1.00000000e+00, 4.96400751e-27],\n",
       "       [9.99992023e-01, 7.97745444e-06],\n",
       "       [1.00000000e+00, 2.62669718e-12],\n",
       "       [9.82692514e-01, 1.73074857e-02]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_gnb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스를 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype='<U6')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4.])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.class_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.41750002, 132.5       ,   7.5       ],\n",
       "       [  5.85500002, 176.25      ,  11.25      ]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.29194841e-02, 4.18750001e+02, 1.25000073e+00],\n",
       "       [2.62757494e-02, 9.21875007e+01, 6.87500734e-01]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.sigma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype='<U6')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.predict([[6,130,8],[6,180,12]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 다항 베이지안 multinomial Bayesian\n",
    "\n",
    "**다항모델 Multinomial Bayesian**은 앞서 이항분포가 사건의 발생여부에 따른 이진적이었다면, 다항분포는 단어의 발생빈도에 따라 문서를 분류하는 문제를 예로 들 수 있다. 단어가 1번 발생할 확률, 2번 발생할 확률을 계산하게 된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  계산\n",
    "\n",
    "속성의 집합 x = (x1,...,xn), 그리고 Ck (k개의 클래스), 추론은 최대의 사후확률 $p(C_k | x_1,\\ldots,x_n)$로 결정된다.\n",
    "\n",
    "$posterior = \\frac{prior \\times likelihood}{evidence}$\n",
    "\n",
    "$P(C_k \\vert x) = \\frac{P(C_k) \\ P(x \\vert C_k)}{P(x)}$\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(C_k \\vert x_1, \\dots, x_n)\n",
    "    & \\varpropto P(C_k, x_1, \\dots, x_n) \\\\\n",
    "    & \\varpropto P(C_k) P(x_1 \\vert C_k) \\\n",
    "         P(x_2\\vert C_k) P(x_3\\vert C_k) \\cdots \\\\\n",
    "    & \\varpropto P(C_k) \\prod_{i=1}^n P(x_i \\vert C_k)\n",
    "\\end{align}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 예제\n",
    "\n",
    "문서가 다음가 같이 주어졌다고 하자.\n",
    "문서는:\n",
    "* **문장**으로 분리한다. 이 경우 문장을 나누는 기준이 단순히 '.'으로 분리하기 쉽지 않을 수 있다. Mr. 같은 약어에 점을 포함되거나, 의문부호로 문장을 끝내거나, 마침표로 끝내지 않는 경우도 있기 때문이다.\n",
    "* **단어**로 분리한다. 단어로 분리되면, Bag of Words 모델에 따라, 단어의 앞 뒤에 무엇이 왔는지 무시되고, 오로지 단어의 집합으로 구성된다.\n",
    "* **품사**도 식별할 필요가 있다. 한국어는 조사가 붙어 격변화를 하고, 형용사도 다양하게 변화하므로 어근을 추출해 사용하기도 한다.\n",
    "* **불용어**는 제거해준다.\n",
    "\n",
    "이렇게 추출된 단어로 word vector를 생성한다. word vector는 (단어 key, 값 value)로 구성되면, 이 경우 값은 단어존재, 단어빈도, TF-IDF 등이 사용된다.\n",
    "\n",
    "베이지안과 같은 지도기계학습을 적용하기 위해서는, 각 문서에 대해 분류가 선행되어야 한다. 이를 위해서 별도로 판정 작업이 필요하다.\n",
    "문서 1, 3, 4, 6, 8, 9는 부정적, 반면에 문서2, 5, 7, 10 4건은 긍정적이다.\n",
    "부정의 label은 0, 긍정의 label은 1로 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서번호 | 문서 | 단어 | 클래스\n",
    "-----|------|------|------\n",
    "1 | I am sorry he has fleas poor dog | 'sorry','fleas','poor','dog' | 1\n",
    "2 | take the dog to the park my dog would love it | 'dog','park','dog','love' | 0\n",
    "3 | quit posting stupid worthless garbage | 'quit','posting','stupid','worthless','garbage' | 1\n",
    "4 | my dog has fleas quit buying worthless dog food stupid' | 'dog','fleas','quit','buying','worthless','dog','food','stupid' | 1\n",
    "5 | dog is so cute I love him | 'dog','cute','love' | 0\n",
    "6 | 강아지 벼룩 미안해 불쌍해 | '강아지','벼룩','미안해','불쌍해' | 1\n",
    "7 | 강아지 공원 강아지 좋아해 | '강아지','공원','강아지','좋아해' | 0\n",
    "8 | 멍청하게 쓸데없는 쓰레기 포스팅 | '멍청하게','쓸데없는','쓰레기','포스팅' | 1\n",
    "9 | 강아지 벼룩 쓸데없는 강아지 음식 사지마 멍청하게 | '강아지','벼룩','쓸데없는','강아지','음식','사지마','멍청하게' | 1\n",
    "10 | 강아지 귀여워 좋아해 | '강아지','귀여워','좋아해' | 0\n",
    "11 | my love my dog has fleas poor dog | 'dog','dog','fleas','love','poor' | ?\n",
    "12 | 강아지 벼룩 멍청하게 | '강아지','벼룩', '멍청하게' | ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사전확률\n",
    "\n",
    "* 총문서 10건\n",
    "    * 문서(0)은 4\n",
    "    * 문서(1)은 6\n",
    "\n",
    "* P(1) prior = $\\frac{N_1}{N} = \\frac{6}{10} = 0.6$ 총 10개 문서 중 6개\n",
    "* P(0) prior = $\\frac{N_0}{N} = \\frac{4}{10} = 0.4$ 총 10개 문서 중 4개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 조건확률\n",
    "\n",
    "* 전체 단어빈도 46 (영어 24 + 한글 22)\n",
    "    * 긍정(0)일때 전체 단어빈도 14 (중복제거 8: 'dog','park','love','cute','강아지','공원','좋아해','귀여워')\n",
    "    * 부정(1)일때 전체 단어빈도 32 (중복제거 21: 'sorry','fleas','poor','dog','quit','posting','stupid','worthless','garbage' ,'buying','food','강아지','벼룩','미안해','불쌍해','멍청하게','쓸데없는','쓰레기','포스팅','음식','사지마')\n",
    "* 전체 단어빈도 (중복제거) 27 (영어: 4 + 2 + 5 + 2 + 1, 한글: 4 + 2 + 4 + 2 + 1 = 14 + 13)\n",
    "\n",
    "'sorry'의 조건확률\n",
    "* P(sorry|1) = $\\frac{N_{sorry|1} + 1}{N_1 + N_{voca}} = \\frac{1+1}{32+27} = 0.03389831$\n",
    "\n",
    "'dog'의 조건확률이다. 이 단어는 양 쪽에 모두 3회 나타난다.\n",
    "* P(dog|0) = $\\frac{N_{dog|0} + 1}{N_1 + N_{voca}} = \\frac{3+1}{14+27} = 0.09756098$\n",
    "* P(dog|1) = $\\frac{N_{dog|1} + 1}{N_1 + N_{voca}} = \\frac{3+1}{32+27} = 0.06779661$\n",
    "\n",
    "'쓸데없는' 단어의 조건확률이다.\n",
    "* P(쓸데없는|0) = $\\frac{N_{쓸데없는|0} + 1}{N_1 + N_{voca}} = \\frac{0+1}{14+27} = 0.02439024$\n",
    "* P(쓸데없는|1) = $\\frac{N_{쓸데없는|1} + 1}{N_1 + N_{voca}} = \\frac{2+1}{32+27} = 0.05084746$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측\n",
    "\n",
    "dog 2회, fleas, love, poor를 예측하면\n",
    "* post1 = prior1 x likelihood1 = prior1 x p(dog|1) x p(dog|1) x p(fleas|1) x p(poor|0) x p(love|0)\n",
    "* post0 = prior1 x likelihood1 = prior0 x p(dog|0) x p(dog|0) x p(fleas|0) x p(poor|0) x p(love|0)\n",
    "\n",
    "이 계산에 필요한 조건부 확률은:\n",
    "* p(dog|0) = 0.09756098\n",
    "* p(fleas|0) = 0.02439024\n",
    "* p(poor|0) = 0.02439024\n",
    "* p(love|0) = 0.07317073\n",
    "\n",
    "* p(dog|1) = 0.06779661\n",
    "* p(fleas|1) = 0.05084746\n",
    "* p(poor|1) = 0.03389831\n",
    "* p(love|1) = 0.01694915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post0: 0.0000001657226369\n",
      "post1: 0.0000000805679737\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# dog^2 * fleas * poor * love\n",
    "print(\"post0: {:.16f}\".format(0.4*math.pow(0.09756098,2)*0.02439024*0.02439024*0.07317073))\n",
    "# dog^2 * fleas * poor * love\n",
    "print(\"post1: {:.16f}\".format(0.6*math.pow(0.06779661,2)*0.05084746*0.03389831*0.01694915))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "0일 경우의 사후확률 post0: 0.0000001657226369은 1일 경우의 사후확률 post1: 0.0000000805679737보다 크다. 그러므로 0으로 결정하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터\n",
    "\n",
    "앞서 구성한 텍스트 데이터를 가지고, d1, ..., d10을 구성한다.\n",
    "d1, d3, d4, d6, d8, d9는 부정적이고 d2, d5, d7, d10 4건은 긍정적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postingList=[['sorry','fleas','poor','dog'],\n",
    "             ['dog','park','dog','love'],\n",
    "             ['quit','posting','stupid','worthless','garbage'],\n",
    "             ['dog','fleas','quit','buying','worthless','dog','food','stupid'],\n",
    "             ['dog','cute','love'],\n",
    "             ['강아지','벼룩','미안해','불쌍해'],\n",
    "             ['강아지','공원','강아지','좋아해'],\n",
    "             ['멍청하게','쓸데없는','쓰레기','포스팅'],\n",
    "             ['강아지','벼룩','쓸데없는','강아지','음식','사지마','멍청하게'],\n",
    "             ['강아지','귀여워','좋아해']]\n",
    "classVec = [1,0,1,1,0,1,0,1,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 단어목록\n",
    "\n",
    "#### 단어의 목록은 집합으로\n",
    "\n",
    "단어목록은 set로 선언하여, 중복이 없는 단어들을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabSet=set([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add() 함수로 set에 단어들을 저장할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"vacabSet: {'Seoul'}\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabSet.add(\"Seoul\")\n",
    "f\"vacabSet: {vocabSet}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 배열과 다른 특징이 있다. set은 중복을 허용하지 않는다. 동일한 문자열을 또 입력해도, 하나만 보관된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"vacabSet: {'Seoul'}\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabSet.add(\"Seoul\")\n",
    "f\"vacabSet: {vocabSet}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 깨끗하게 비우고 시작하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vacabSet: set()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabSet.clear()\n",
    "f\"vacabSet: {vocabSet}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 합집합\n",
    "문서로부터 단어를 하나씩 추가하는데, 이미 있는 단어가 등장하는 경우가 흔하다.\n",
    "따라서 중복을 막기 위해, union 연산 \"|\"으로 합집합을 구하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Seoul', 'Sydney', 'New York', 'Tokyo'}\n"
     ]
    }
   ],
   "source": [
    "citiesA = set([\"Seoul\",\"Sydney\",\"Tokyo\"])\n",
    "citiesB = set([\"Seoul\",\"New York\"])\n",
    "citiesAll = citiesA|citiesB\n",
    "print(citiesAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 줄씩 단어를 가져와 set()로 중복이 없도록 골라내고, 현재의 vacabSet에 더해가면서 중복이 없는 단어의 목록으로 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in postingList:\n",
    "    #vocaSet = vocaSet.union(set(doc))\n",
    "    vocabSet=vocabSet | set(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복이 없는, 단어의 갯수와 목록을 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n of vocab: 27\n",
      "voca: {'dog', 'worthless', 'food', 'cute', '사지마', '귀여워', '벼룩', '불쌍해', 'buying', '공원', '음식', '포스팅', 'quit', '멍청하게', 'posting', '쓸데없는', '미안해', 'fleas', '강아지', '쓰레기', 'poor', 'stupid', '좋아해', 'sorry', 'love', 'park', 'garbage'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"n of vocab: {0}\\nvoca: {1}\\n\".format(len(vocabSet),vocabSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 단어 벡터\n",
    "\n",
    "단어벡터 Word Vector는 단어빈도로 구성된 배열을 말한다.\n",
    "이를 구성하기 위해서는:\n",
    "* **중복되지 않는 단어목록**을 구하고, 몇 개의 단어인지 알아낸다.\n",
    "* 단어의 수만큼 단어벡터를 만들고, **초기화**한다.\n",
    "* 문서의 단어벡터에 **단어빈도**를 입력한다.\n",
    "* 모든 문장에 단어별 빈도를 저장한 **단어벡터**를 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어벡터 크기 결정해서 초기화\n",
    "\n",
    "vocabSet는 중복되지 않는 단어목록을 가지고 있다.\n",
    "set은 리스트와 달리 순서가 없는 특징이 있으므로 **indexing**기능을 사용할 수 없다.\n",
    "우리는 단어의 indexing이 필요하므로 set을 리스트로 변환해서 사용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabList=list(vocabSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 수만큼 단어벡터의 크기를 정하자.\n",
    "0으로 초기화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordVec = [0]*len(vocabList)\n",
    "wordVec = [0]*len(vocabSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력해보면, 앞서 찾아낸 중복없는 단어의 갯수만큼 word vector가 설정된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordVec: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"wordVec: {}\".format(wordVec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한 문장을 단어벡터로 만들어 보기\n",
    "\n",
    "문장은 이미 단어로 분리되어 있다. 단어별로 초기화된 단어벡터에 빈도를 입력해보자.\n",
    "빈도는 단순히 1로 하거나, 발생빈도를 그대로 적을 수 있다.\n",
    "**단어목록에 없는 경우**에는 문제가 된다. 앞서 단어목록을 만들면서 빼먹은 경우인데, 새로 문장이 등장하면 그런 경우가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...inserting 'dog'\n",
      "...inserting 'park'\n",
      "...inserting 'dog'\n",
      "...inserting 'love'\n"
     ]
    }
   ],
   "source": [
    "for word in postingList[1]:\n",
    "    if word in vocabList:\n",
    "        print (\"...inserting '{}'\".format(word))\n",
    "        #returnVec[vocabList.index(word)] = 1 # 0 if none, 1 if exists\n",
    "        wordVec[vocabList.index(word)] += 1 # num of frequencies\n",
    "    else:\n",
    "        print (\"the word: %s is not in my Vocabulary!\".format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 단어벡터의 단어 순서대로 빈도가 적혀졌다. 발생한 빈도가 적혀지니까, 2회 발생한 경우는 2로 1회는 1로 적힌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 27 word vector: [0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print (\"len: {} word vector: {}\".format(len(wordVec), wordVec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수로 만들기\n",
    "\n",
    "단어벡터를 만드는 기능은 모든 문서에 대해 실행되어야 한다.\n",
    "앞서 단어벡터 만드는 작업을 함수로 만들어 실행하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function setOfWords2Vec\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    wordVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            #wordVec[vocabList.index(word)] = 1 # 0 if none, 1 if exists\n",
    "            wordVec[vocabList.index(word)] += 1 # num of frequencies\n",
    "        else: print (\"the word: '{}' is not in my Vocabulary!\".format(word))\n",
    "    return wordVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어벡터 생성\n",
    "\n",
    "모든 문장에 대해 단어별 빈도를 저장한 훈련단어벡터를 생성해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMat=[]\n",
    "for postinDoc in postingList:\n",
    "    trainMat.append(setOfWords2Vec(vocabList, postinDoc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련단어벡터를 출력하면, 문장의 수 6개별로 단어의 수 32개에 대해 빈도를 0, 1로 표시하여 출력하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word vector: [[1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"word vector: {trainMat}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (3) 사전확률\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainNB0\n",
    "# nword_doc-np.zeros([nword,ndoc])\n",
    "numTrainDocs=len(trainMat) #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num of Train Docs: 10'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"num of Train Docs: {numTrainDocs}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classVec.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior1 = classVec.count(1)/numTrainDocs\n",
    "prior0 = classVec.count(0)/numTrainDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prior for 1: 0.6 prior for 0: 0.4'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"prior for 1: {prior1} prior for 0: {prior0}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 우도\n",
    "\n",
    "$\\frac{\\displaystyle 해당단어빈도 numWords + 1}{\\displaystyle 총단어빈도 totalNumWords + 고유단어수 vocab}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 고유단어수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V=len(vocabSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Num of unique words: 27'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Num of unique words: {V}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 클래스별 총단어빈도, 해당 단어빈도\n",
    "\n",
    "분모, 분자로 나누어 계산한다.\n",
    "분모는 클래스별 총단어빈도를,\n",
    "분자에는 해당 단어빈도를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p0Num = np.zeros(V)\n",
    "p1Num = np.zeros(V)\n",
    "p0Denom = 0.0\n",
    "p1Denom = 0.0  # numWords with repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우도의 분모, 분자를 구한다.\n",
    "각 클래스의 전체 단어수와 해당 훈련데이터의 단어빈도를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. class:1 빈도합:[1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1.]\n",
      "1. class:0 빈도합:[0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "2. class:1 빈도합:[1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1.]\n",
      "3. class:1 빈도합:[2. 0. 0. 0. 1. 1. 0. 0. 0. 3. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 2. 2. 1.\n",
      " 2. 0. 1.]\n",
      "4. class:0 빈도합:[0. 0. 1. 2. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0.]\n",
      "5. class:1 빈도합:[2. 0. 0. 0. 1. 1. 1. 0. 0. 3. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 2. 2. 1.\n",
      " 2. 0. 1.]\n",
      "6. class:0 빈도합:[0. 0. 1. 2. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0.]\n",
      "7. class:1 빈도합:[2. 0. 0. 0. 1. 1. 1. 1. 1. 3. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 2. 2. 1.\n",
      " 2. 0. 1.]\n",
      "8. class:1 빈도합:[2. 1. 0. 0. 1. 1. 1. 2. 2. 3. 1. 1. 2. 1. 0. 1. 1. 1. 3. 0. 0. 2. 2. 1.\n",
      " 2. 0. 1.]\n",
      "9. class:0 빈도합:[0. 0. 1. 2. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 1. 0. 0. 0. 3. 1. 2. 0. 0. 0.\n",
      " 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(numTrainDocs):\n",
    "    if classVec[i] == 1:\n",
    "        p1Num += trainMat[i]\n",
    "        p1Denom += sum(trainMat[i])\n",
    "        print (\"{}. class:{} 빈도합:{}\".format(i,classVec[i],p1Num))\n",
    "    else:\n",
    "        p0Num += trainMat[i]\n",
    "        p0Denom += sum(trainMat[i])\n",
    "        print (\"{}. class:{} 빈도합:{}\".format(i,classVec[i],p0Num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드에서 각 클래스의 총단어빈도를 계산하였다.\n",
    "**총단어빈도**는 클래스 0에 14개, 클래스2에 32개이다.\n",
    "단 이들은 중복이 허용된 숫자이므로, 합한다고 해서 vacabSet에 있는 27과 같지 않다.\n",
    "분자인 단어빈도를 모두 더하면 당연히 분모인 총단어빈도가 된다.\n",
    "\n",
    "자, 이제 계산을 해보자.\n",
    "* 0에 대해, p0Denom은 총단어빈도에 해당하고 14이다.\n",
    "3번째 값은 단어빈도 1이다. 이를 총단어빈도 14로 나누어 계산한다.\n",
    "```python\n",
    "0.07142857 = 1/14 (단어빈도/총단어빈도)\n",
    "```\n",
    "\n",
    "* 1에 대해서도 마찬가지이다. 단어빈도 1인경우 총단어빈도 32로 나누어 계산한다.\n",
    "```python\n",
    "0.03125 = 1/32 (단어빈도/총단어빈도)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1Vect = p1Num/p1Denom\n",
    "p0Vect = p0Num/p0Denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---p0:\n",
      "p0Num=\n",
      "[0. 0. 1. 2. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 1. 0. 0. 0. 3. 1. 2. 0. 0. 0.\n",
      " 0. 1. 0.]\n",
      "p0Denom=14.0\n",
      "p0Vect\n",
      "[0.         0.         0.07142857 0.14285714 0.         0.\n",
      " 0.         0.         0.         0.21428571 0.         0.\n",
      " 0.         0.         0.07142857 0.         0.         0.\n",
      " 0.21428571 0.07142857 0.14285714 0.         0.         0.\n",
      " 0.         0.07142857 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print (\"---p0:\\np0Num=\\n{0}\\np0Denom={1}\\np0Vect\\n{2}\".format(p0Num, p0Denom, p0Vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---p1:\n",
      " p1Num=\n",
      "[2. 1. 0. 0. 1. 1. 1. 2. 2. 3. 1. 1. 2. 1. 0. 1. 1. 1. 3. 0. 0. 2. 2. 1.\n",
      " 2. 0. 1.]\n",
      "p1Denom=32.0\n",
      "p1Vect\n",
      "[0.0625  0.03125 0.      0.      0.03125 0.03125 0.03125 0.0625  0.0625\n",
      " 0.09375 0.03125 0.03125 0.0625  0.03125 0.      0.03125 0.03125 0.03125\n",
      " 0.09375 0.      0.      0.0625  0.0625  0.03125 0.0625  0.      0.03125]\n"
     ]
    }
   ],
   "source": [
    "print (\"---p1:\\n p1Num=\\n{0}\\np1Denom={1}\\np1Vect\\n{2}\".format(p1Num, p1Denom, p1Vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 스무딩을 해보자.\n",
    "스무딩을 하지 않으면 0으로 연산하면서 문제가 될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1Vect=(p1Num+1)/(p1Denom+V)\n",
    "p0Vect=(p0Num+1)/(p0Denom+V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---p0:\n",
      "p0Num=\n",
      "[1. 1. 2. 3. 1. 1. 1. 1. 1. 4. 1. 1. 1. 1. 2. 1. 1. 1. 4. 2. 3. 1. 1. 1.\n",
      " 1. 2. 1.]\n",
      "p0Denom=41.0\n",
      "p0Vect\n",
      "[0.02439024 0.02439024 0.04878049 0.07317073 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.09756098 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.04878049 0.02439024 0.02439024 0.02439024\n",
      " 0.09756098 0.04878049 0.07317073 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.04878049 0.02439024]\n"
     ]
    }
   ],
   "source": [
    "print (\"---p0:\\np0Num=\\n{0}\\np0Denom={1}\\np0Vect\\n{2}\".format(p0Num+1, p0Denom+V, p0Vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---p1:\n",
      " p1Num=\n",
      "[2. 1. 0. 0. 1. 1. 1. 2. 2. 3. 1. 1. 2. 1. 0. 1. 1. 1. 3. 0. 0. 2. 2. 1.\n",
      " 2. 0. 1.]\n",
      "p1Denom=32.0\n",
      "p1Vect\n",
      "[0.05084746 0.03389831 0.01694915 0.01694915 0.03389831 0.03389831\n",
      " 0.03389831 0.05084746 0.05084746 0.06779661 0.03389831 0.03389831\n",
      " 0.05084746 0.03389831 0.01694915 0.03389831 0.03389831 0.03389831\n",
      " 0.06779661 0.01694915 0.01694915 0.05084746 0.05084746 0.03389831\n",
      " 0.05084746 0.01694915 0.03389831]\n"
     ]
    }
   ],
   "source": [
    "print (\"---p1:\\n p1Num=\\n{0}\\np1Denom={1}\\np1Vect\\n{2}\".format(p1Num, p1Denom, p1Vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'dog'은 양쪽에 각 3회씩 등장한다. 우도를 구해보면 각 p(dog|0)=0.09756098, p(dog|1)=0.06779661 이다.\n",
    "* P(dog|0) = $\\frac{N_{dog|0} + 1}{N_1 + N_{voca}} = \\frac{3+1}{14+27} = 0.09756098$\n",
    "* P(dog|1) = $\\frac{N_{dog|1} + 1}{N_1 + N_{voca}} = \\frac{3+1}{32+27} = 0.06779661$\n",
    "\n",
    "단어벡터의 2번째 위치를 차지하는 '쓸데없는'은 부정(1)인 경우에만 등장한다.\n",
    "* P(쓸데없는|0) = $\\frac{N_{쓸데없는|0} + 1}{N_1 + N_{voca}} = \\frac{0+1}{14+27} = 0.02439024$\n",
    "* P(쓸데없는|1) = $\\frac{N_{쓸데없는|1} + 1}{N_1 + N_{voca}} = \\frac{2+1}{32+27} = 0.05084746$\n",
    "\n",
    "이때 주의해야 할 점은, 인덱스 값을 순서를 찾아서 인덱스로 사용하면 안된다.\n",
    "인덱스는 Set에서 리스트를 생성하면서 순서가 변경되기 때문이다.\n",
    "**index() 함수로 인덱스를 찾아서** 사용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0975609756097561, 0.06779661016949153)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0Vect[vocabList.index('dog')], p1Vect[vocabList.index('dog')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.024390243902439025, 0.05084745762711865)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0Vect[vocabList.index('쓸데없는')], p1Vect[vocabList.index('쓸데없는')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 예측\n",
    "\n",
    "\"my dog has fleas stupid\" 또는 \"강아지 벼룩 멍청하게\" 이런 한, 영 문장으로 분류를 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률계산을 할 때, 없었던 단어를 제거하면, dog, fleas, love, poor, dog이란 단어가 남는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word: 'my' is not in my Vocabulary!\n",
      "the word: 'has' is not in my Vocabulary!\n",
      "the word: 'problems' is not in my Vocabulary!\n",
      "the word: 'him' is not in my Vocabulary!\n"
     ]
    }
   ],
   "source": [
    "# classifyNB\n",
    "import math\n",
    "# my dog has flea problems. Love him, poor dog.\n",
    "testEntry1 = ['my', 'dog', 'has', 'fleas', 'problems', 'love', 'him', 'poor', 'dog']\n",
    "#testEntry1 = ['love', 'cute', 'dog']\n",
    "testData1 = np.array(setOfWords2Vec(vocabList, testEntry1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word: '어쩌나' is not in my Vocabulary!\n"
     ]
    }
   ],
   "source": [
    "testEntry2 = ['강아지', '불쌍해', '미안해', '어쩌나']\n",
    "testData2 = np.array(setOfWords2Vec(vocabList, testEntry2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 5개 dog, fleas, love, poor, dog에 대해, 2회 발생한 dog과 나머지 단어에 대해 빈도가 기록된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 단어 3개에 대해 빈도가 기록된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 리스트 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "post1 = prior1 * \\\n",
    "        math.pow(p1Vect[vocabList.index('dog')],2) * \\\n",
    "        p1Vect[vocabList.index('fleas')] * \\\n",
    "        p1Vect[vocabList.index('poor')] * \\\n",
    "        p1Vect[vocabList.index('love')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post1: 0.0000000806\n"
     ]
    }
   ],
   "source": [
    "print(\"post1: {:.10f}\".format(post1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "post0 = prior0 * \\\n",
    "        math.pow(p0Vect[vocabList.index('dog')],2) * \\\n",
    "        p0Vect[vocabList.index('fleas')] * \\\n",
    "        p0Vect[vocabList.index('poor')] * \\\n",
    "        p0Vect[vocabList.index('love')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post0: 0.0000001657\n"
     ]
    }
   ],
   "source": [
    "print(\"post0: {:.10f}\".format(post0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사후확률 1이 사후확률 0보다 크다. 따라서 0, 즉 **긍정**으로 예측된다.\n",
    "앞서 계산한 **가중치를 보면 dog은 긍정단어**로 계산되었다.\n",
    "부정단어 fleas, poor가 있다고 하더라도, dog과 더불어 love 단어가 사용되어서 0으로 예측된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post1>post0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### power\n",
    "\n",
    "동전의 앞면이 나올 확률은 0.5, 2회 연속 앞면이 나올 확률은 제곱을 해야 하고 0.25가 된다.\n",
    "```**```는 요소별 연산을 해서, $0.5^2$와 $0.5^1$의 결과 0.25, 0.5가 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.5 ])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([0.5,0.5])**np.array([2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```**``` 대신 np.power() 함수를 사용해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.5 ])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(np.array([0.5,0.5]),np.array([2,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### product\n",
    "\n",
    "앞면이 2회 나오는 확률은 제곱을 하고, 이처럼 **거듭되는 확률은 곱셈연산**을 해서 계산한다.\n",
    "np.prod() 함수는 모든 요소의 곱셈 계산을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Product은 곱셈을 의미한다. $\\prod_{n=2}^4\\ n = 2 \\times 3 \\times 4 = 24$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(np.power(np.array([0.5,0.5]), np.array([2,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사후확률은:\n",
    "* 사전확률에\n",
    "* 해당단어의 발생확률에 빈도를 제곱한 후 (```np.power(p1Vect, testData1)```), 모두 곱셈 ```np.prod()```하여 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post1: 0.0000000805679707\n"
     ]
    }
   ],
   "source": [
    "post1=prior1*np.prod(np.power(p1Vect, testData1))\n",
    "print(\"post1: {:.16f}\".format(post1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post0: 0.0000001657226789\n"
     ]
    }
   ],
   "source": [
    "post0=prior0*np.prod(np.power(p0Vect, testData1))\n",
    "print(\"post0: {:.16f}\".format(post0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post1>post0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) sklearn\n",
    "\n",
    "* X는 배열이나 희소행렬 shape (n_samples, n_features)로 구성\n",
    "* y는 배열 shape (n_samples,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 27)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainMat).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(classVec).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trainMat, classVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측\n",
    "\n",
    "testData1은 0, testData2는 1로 예측되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([testData1, testData2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/bin/python3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"myApp\")\\\n",
    "    .config(conf=myConf)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터\n",
    "\n",
    "데이터는 label, features로 구성하도록 하자.\n",
    "다음과 같이 단어로 입력해도 좋지만, 여기서는 단어분리와 불용어 제거를 직접 해보자.\n",
    "한글은 unicode로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        [1,'I am sorry he has fleas poor dog'],\n",
    "        [0,'take the dog to the park my dog would love it'],\n",
    "        [1,'quit posting stupid worthless garbage'],\n",
    "        [1,'my dog has fleas quit buying worthless dog food stupid'],\n",
    "        [0,'dog is so cute I love him'],\n",
    "        [1,u'우리 강아지 벼룩 미안해 불쌍해'],\n",
    "        [0,u'강아지 공원 강아지 좋아해'],\n",
    "        [1,u'너 멍청하게 쓸데없는 쓰레기 포스팅'],\n",
    "        [1,u'강아지 벼룩 쓸데없는 강아지 음식 사지마 멍청하게'],\n",
    "        [0,u'나 강아지 귀여워 좋아해']\n",
    "    ],\n",
    "    ['cls','sent']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스키마를 살펴보면, cls는 정수, sent는 문자열로 인식되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cls: long (nullable = true)\n",
      " |-- sent: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### StringIndexer\n",
    "문자열 컬럼을 label index로 변환\n",
    "우리의 경우는 정수이다. 이 경우는 정수를 문자열로 변환하고 난 후 label index로 변환한다.\n",
    "빈도수가 높은 문자열이 0이 배정된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"cls\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RegexTokenizer\n",
    "텍스트를 분리해서 단어로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "regexTok = RegexTokenizer(inputCol=\"sent\", outputCol=\"wordsRegex\", pattern=\"\\\\s+\")\n",
    "#tokenizer = Tokenizer(inputCol=\"sent\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 불용어\n",
    "\n",
    "단어에서 Stopwords를 제거하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "stop = StopWordsRemover(inputCol=\"wordsRegex\", outputCol=\"nostops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords=list()\n",
    "_stopwords=stop.getStopWords()\n",
    "for e in _stopwords:\n",
    "    stopwords.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 u\"나\",u\"너\", u\"우리\"와 영어 \"take\"를 제거한다. 영어단어는 불용어 사전을 이용하고, \"take\"는 앞의 예제와 일치시키기 위해 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_mystopwords=[u\"나\",u\"너\", u\"우리\", \"take\"]\n",
    "for e in _mystopwords:\n",
    "    stopwords.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StopWordsRemover_ead00dd9750a"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop.setStopWords(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HashingTF\n",
    "단어 -> word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"nostops\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer,regexTok,stop,hashingTF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pipeline.fit(df)\n",
    "trainDf = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------------------------------------------+------------------------------------------------------------------------------------+\n",
      "|label|nostops                                                 |features                                                                            |\n",
      "+-----+--------------------------------------------------------+------------------------------------------------------------------------------------+\n",
      "|0.0  |[sorry, fleas, poor, dog]                               |(262144,[6155,54556,85735,144961],[1.0,1.0,1.0,1.0])                                |\n",
      "|1.0  |[dog, park, dog, love]                                  |(262144,[54556,71826,186480],[2.0,1.0,1.0])                                         |\n",
      "|0.0  |[quit, posting, stupid, worthless, garbage]             |(262144,[1696,67357,111492,186022,247840],[1.0,1.0,1.0,1.0,1.0])                    |\n",
      "|0.0  |[dog, fleas, quit, buying, worthless, dog, food, stupid]|(262144,[1696,6155,54556,111492,121133,186022,258147],[1.0,1.0,2.0,1.0,1.0,1.0,1.0])|\n",
      "|1.0  |[dog, cute, love]                                       |(262144,[23837,54556,186480],[1.0,1.0,1.0])                                         |\n",
      "|0.0  |[강아지, 벼룩, 미안해, 불쌍해]                          |(262144,[5579,58749,60868,226029],[1.0,1.0,1.0,1.0])                                |\n",
      "|1.0  |[강아지, 공원, 강아지, 좋아해]                          |(262144,[1510,58749,242045],[1.0,2.0,1.0])                                          |\n",
      "|0.0  |[멍청하게, 쓸데없는, 쓰레기, 포스팅]                    |(262144,[81961,173322,185814,200546],[1.0,1.0,1.0,1.0])                             |\n",
      "|0.0  |[강아지, 벼룩, 쓸데없는, 강아지, 음식, 사지마, 멍청하게]|(262144,[3425,58749,60868,185814,200546,250881],[1.0,2.0,1.0,1.0,1.0,1.0])          |\n",
      "|1.0  |[강아지, 귀여워, 좋아해]                                |(262144,[58749,64077,242045],[1.0,1.0,1.0])                                         |\n",
      "+-----+--------------------------------------------------------+------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDf.select(\"label\",\"nostops\",\"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련데이터\n",
    "\n",
    "label은 double, features는 vector 타입으로 맞추어 주었는지 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cls: long (nullable = true)\n",
      " |-- sent: string (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- wordsRegex: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- nostops: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+\n",
      "|cls|label|            features|\n",
      "+---+-----+--------------------+\n",
      "|  1|  0.0|(262144,[6155,545...|\n",
      "|  0|  1.0|(262144,[54556,71...|\n",
      "|  1|  0.0|(262144,[1696,673...|\n",
      "|  1|  0.0|(262144,[1696,615...|\n",
      "|  0|  1.0|(262144,[23837,54...|\n",
      "|  1|  0.0|(262144,[5579,587...|\n",
      "|  0|  1.0|(262144,[1510,587...|\n",
      "|  1|  0.0|(262144,[81961,17...|\n",
      "|  1|  0.0|(262144,[3425,587...|\n",
      "|  0|  1.0|(262144,[58749,64...|\n",
      "+---+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDf.select('cls','label','features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링\n",
    "Spark에서는 pyspark.ml.classification의 NaiveBayes 모델을 사용한다.\n",
    "\n",
    "```python\n",
    "(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction', smoothing=1.0, modelType='multinomial', thresholds=None, weightCol=None)\n",
    "```\n",
    "* smoothing 0보다 큰 값을 입력해야 하고, 기본값은 1.0\n",
    "* modelType은 \"multinomial\" (기본 값), \"bernoulli\" 2가지를 지원한다.\n",
    "TF-IDF와 같은 값은 쓰이면 multinomial을 사용한다.\n",
    "반면에 존재한다 아니다 0/1로 표시한 경우, bernoulli로 해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb=NaiveBayes(featuresCol='features', labelCol='label', modelType='multinomial', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nb.fit(trainDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래별 사전확률을 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.539, -0.8755])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스의 조건확률을 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(2, 262144, [-12.4768, -12.4768, -12.4768, -12.4768, -12.4768, -12.4768, -12.4768, -12.4768, ..., -12.4767, -12.4767, -12.4767, -12.4767, -12.4767, -12.4767, -12.4767, -12.4767], 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측\n",
    "\n",
    "데이터가 적어서, train, test로 분리되어 있지 않다.\n",
    "테스트 데이터로 예측해보려면, 데이터는 DataFrame으로 넘겨주어야 한다. **컬럼명을 알아야** 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.transform(trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cls: bigint, sent: string, label: double, wordsRegex: array<string>, nostops: array<string>, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------+----------+\n",
      "|label|                              sent|prediction|\n",
      "+-----+----------------------------------+----------+\n",
      "|  0.0|              I am sorry he has...|       0.0|\n",
      "|  1.0|              take the dog to t...|       1.0|\n",
      "|  0.0|              quit posting stup...|       0.0|\n",
      "|  0.0|              my dog has fleas ...|       0.0|\n",
      "|  1.0|              dog is so cute I ...|       1.0|\n",
      "|  0.0|    우리 강아지 벼룩 미안해 불쌍해|       0.0|\n",
      "|  1.0|         강아지 공원 강아지 좋아해|       1.0|\n",
      "|  0.0|너 멍청하게 쓸데없는 쓰레기 포스팅|       0.0|\n",
      "|  0.0| 강아지 벼룩 쓸데없는 강아지 음...|       0.0|\n",
      "|  1.0|           나 강아지 귀여워 좋아해|       1.0|\n",
      "+-----+----------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('label','sent','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가\n",
    "\n",
    "BinaryClassificationEvaluator는 두 개의 컬럼 rawPrediction과 label을 서로 비교해서 정확성을 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "#evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제: 트윗 정서 분석\n",
    "\n",
    "트윗의 정서를 분석해보자.\n",
    "트윗은 API를 사용하여 수집할 수 있으나, 프로그램도 작성해야 하고 수집에 상당한 시간이 필요하다.\n",
    "또한 트윗 메시지에 대해 긍정인지, 부정인지 정서를 하나 하나 판단해서 태깅해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
